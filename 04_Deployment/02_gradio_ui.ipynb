{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Interactive UIs with Gradio\n",
                "\n",
                "**Module 04 | Notebook 2 of 4**\n",
                "\n",
                "Create beautiful, shareable web interfaces for your ML models in minutes.\n",
                "\n",
                "## Learning Objectives\n",
                "\n",
                "By the end of this notebook, you will be able to:\n",
                "1. Create Gradio interfaces for model inference\n",
                "2. Customize UI components\n",
                "3. Share your demos publicly\n",
                "4. Deploy to Hugging Face Spaces\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "!pip install transformers torch gradio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Gradio version: 5.50.0\n",
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "import gradio as gr\n",
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(f\"Gradio version: {gr.__version__}\")\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Why Gradio?\n",
                "\n",
                "### From Model to Demo in 3 Lines\n",
                "\n",
                "```python\n",
                "import gradio as gr\n",
                "\n",
                "def predict(text):\n",
                "    return model(text)\n",
                "\n",
                "gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\").launch()\n",
                "```\n",
                "\n",
                "### Gradio Features\n",
                "\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| **Quick setup** | Create UIs in minutes |\n",
                "| **Pre-built components** | Text, image, audio, video |\n",
                "| **Public sharing** | Share via link instantly |\n",
                "| **HF Spaces** | Free hosting on Hugging Face |\n",
                "| **API generation** | Automatic REST API |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Basic Sentiment Analysis Interface"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "389d114878f54225ba8c73a14f2fa62a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ff2800af25564efa99d334aff6df597b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b0d120887a2c4c3da065fc8f7f4fa0cf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d864e04a3d6241a589278b0ecbe89f8c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cuda:0\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded: distilbert-base-uncased-finetuned-sst-2-english\n"
                    ]
                }
            ],
            "source": [
                "# Load model\n",
                "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
                "classifier = pipeline(\"sentiment-analysis\", model=model_name, device=0 if torch.cuda.is_available() else -1)\n",
                "\n",
                "print(f\"Model loaded: {model_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üòä POSITIVE (100.0%)\n"
                    ]
                }
            ],
            "source": [
                "# Simple prediction function\n",
                "def predict_sentiment(text):\n",
                "    if not text.strip():\n",
                "        return \"Please enter some text.\"\n",
                "    \n",
                "    result = classifier(text)[0]\n",
                "    emoji = \"üòä\" if result['label'] == 'POSITIVE' else \"üò†\"\n",
                "    return f\"{emoji} {result['label']} ({result['score']:.1%})\"\n",
                "\n",
                "# Test\n",
                "print(predict_sentiment(\"This is amazing!\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
                        "* Running on public URL: https://841d06748a11be986b.gradio.live\n",
                        "\n",
                        "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"https://841d06748a11be986b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Create basic interface\n",
                "demo_basic = gr.Interface(\n",
                "    fn=predict_sentiment,\n",
                "    inputs=gr.Textbox(label=\"Enter text\", placeholder=\"Type your text here...\"),\n",
                "    outputs=gr.Textbox(label=\"Prediction\"),\n",
                "    title=\"Sentiment Analysis\",\n",
                "    description=\"Analyze the sentiment of your text using DistilBERT.\",\n",
                "    examples=[\n",
                "        [\"I absolutely love this product!\"],\n",
                "        [\"This is the worst experience ever.\"],\n",
                "        [\"It's okay, nothing special.\"]\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Launch (set share=True to get a public link)\n",
                "demo_basic.launch(share=True, inline=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Enhanced Interface with Labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
                        "* Running on public URL: https://15a3afe30074247628.gradio.live\n",
                        "\n",
                        "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"https://15a3afe30074247628.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Enhanced prediction with confidence scores\n",
                "def predict_with_scores(text):\n",
                "    if not text.strip():\n",
                "        return {\"Error\": 1.0}\n",
                "    \n",
                "    result = classifier(text)[0]\n",
                "    \n",
                "    # Return as dict for Label component\n",
                "    if result['label'] == 'POSITIVE':\n",
                "        return {\n",
                "            \"POSITIVE üòä\": result['score'],\n",
                "            \"NEGATIVE üò†\": 1 - result['score']\n",
                "        }\n",
                "    else:\n",
                "        return {\n",
                "            \"POSITIVE üòä\": 1 - result['score'],\n",
                "            \"NEGATIVE üò†\": result['score']\n",
                "        }\n",
                "\n",
                "# Create enhanced interface\n",
                "demo_enhanced = gr.Interface(\n",
                "    fn=predict_with_scores,\n",
                "    inputs=gr.Textbox(\n",
                "        label=\"Enter text to analyze\",\n",
                "        placeholder=\"Type or paste your text here...\",\n",
                "        lines=3\n",
                "    ),\n",
                "    outputs=gr.Label(label=\"Sentiment\", num_top_classes=2),\n",
                "    title=\"Advanced Sentiment Analysis\",\n",
                "    description=\"See confidence scores for positive and negative sentiment.\",\n",
                "    examples=[\n",
                "        [\"The movie was great but the ending was disappointing.\"],\n",
                "        [\"Best purchase I've ever made! Highly recommended!\"],\n",
                "        [\"It broke after one day. Complete waste of money.\"]\n",
                "    ],\n",
                "    theme=\"soft\"\n",
                ")\n",
                "\n",
                "demo_enhanced.launch(share=True, inline=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Text Summarization Interface"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cuda:0\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
                        "* Running on public URL: https://cf27f1d78261362a62.gradio.live\n",
                        "\n",
                        "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"https://cf27f1d78261362a62.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load summarization model\n",
                "summarizer = pipeline(\n",
                "    \"summarization\",\n",
                "    model=\"facebook/bart-large-cnn\",\n",
                "    device=0 if torch.cuda.is_available() else -1\n",
                ")\n",
                "\n",
                "def summarize_text(text, max_length, min_length):\n",
                "    if not text.strip() or len(text) < 50:\n",
                "        return \"Please enter at least 50 characters of text.\"\n",
                "    \n",
                "    result = summarizer(\n",
                "        text,\n",
                "        max_length=int(max_length),\n",
                "        min_length=int(min_length),\n",
                "        do_sample=False\n",
                "    )\n",
                "    \n",
                "    return result[0]['summary_text']\n",
                "\n",
                "# Create summarization interface\n",
                "demo_summarize = gr.Interface(\n",
                "    fn=summarize_text,\n",
                "    inputs=[\n",
                "        gr.Textbox(\n",
                "            label=\"Input Text\",\n",
                "            placeholder=\"Paste a long article or text to summarize...\",\n",
                "            lines=10\n",
                "        ),\n",
                "        gr.Slider(50, 200, value=130, step=10, label=\"Max Summary Length\"),\n",
                "        gr.Slider(20, 80, value=30, step=10, label=\"Min Summary Length\")\n",
                "    ],\n",
                "    outputs=gr.Textbox(label=\"Summary\", lines=5),\n",
                "    title=\"üìù Text Summarization\",\n",
                "    description=\"Summarize long texts using BART.\",\n",
                "    examples=[\n",
                "        [\"\"\"The Amazon rainforest, often referred to as the planet's lungs, is a vast \n",
                "        tropical rainforest occupying the Amazon basin in South America. It covers \n",
                "        approximately 5.5 million square kilometers and spans across nine countries, \n",
                "        with Brazil containing the majority. The rainforest houses an estimated \n",
                "        10% of all species on Earth, including over 400 billion trees. However, \n",
                "        deforestation has become a major concern, with thousands of square miles \n",
                "        being cleared annually for agriculture, logging, and development.\"\"\", 100, 30]\n",
                "    ]\n",
                ")\n",
                "\n",
                "demo_summarize.launch(share=True, inline=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Multi-Tab Interface with Blocks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
                        "* Running on public URL: https://a3cb8deadc91ac9bcc.gradio.live\n",
                        "\n",
                        "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"https://a3cb8deadc91ac9bcc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Create a multi-tab application using Blocks\n",
                "with gr.Blocks(title=\"NLP Toolkit\", theme=\"soft\") as demo_blocks:\n",
                "    gr.Markdown(\"# üõ†Ô∏è NLP Toolkit\\nMultiple NLP tasks in one interface.\")\n",
                "    \n",
                "    with gr.Tabs():\n",
                "        # Tab 1: Sentiment Analysis\n",
                "        with gr.TabItem(\"üòä Sentiment\"):\n",
                "            with gr.Row():\n",
                "                with gr.Column():\n",
                "                    sentiment_input = gr.Textbox(\n",
                "                        label=\"Text\",\n",
                "                        placeholder=\"Enter text for sentiment analysis...\",\n",
                "                        lines=3\n",
                "                    )\n",
                "                    sentiment_btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
                "                with gr.Column():\n",
                "                    sentiment_output = gr.Label(label=\"Result\", num_top_classes=2)\n",
                "            \n",
                "            sentiment_btn.click(\n",
                "                fn=predict_with_scores,\n",
                "                inputs=sentiment_input,\n",
                "                outputs=sentiment_output\n",
                "            )\n",
                "        \n",
                "        # Tab 2: Summarization\n",
                "        with gr.TabItem(\"üìù Summarize\"):\n",
                "            with gr.Row():\n",
                "                with gr.Column():\n",
                "                    sum_input = gr.Textbox(\n",
                "                        label=\"Long Text\",\n",
                "                        placeholder=\"Paste text to summarize...\",\n",
                "                        lines=6\n",
                "                    )\n",
                "                    with gr.Row():\n",
                "                        max_len = gr.Slider(50, 200, value=100, label=\"Max Length\")\n",
                "                        min_len = gr.Slider(20, 80, value=30, label=\"Min Length\")\n",
                "                    sum_btn = gr.Button(\"Summarize\", variant=\"primary\")\n",
                "                with gr.Column():\n",
                "                    sum_output = gr.Textbox(label=\"Summary\", lines=4)\n",
                "            \n",
                "            sum_btn.click(\n",
                "                fn=summarize_text,\n",
                "                inputs=[sum_input, max_len, min_len],\n",
                "                outputs=sum_output\n",
                "            )\n",
                "    \n",
                "    gr.Markdown(\"---\\n*Powered by Hugging Face Transformers*\")\n",
                "\n",
                "demo_blocks.launch(share=True, inline=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Deploy to Hugging Face Spaces\n",
                "\n",
                "Create a complete app.py file for Spaces deployment:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ App saved to gradio_app.py\n",
                        "\n",
                        "To deploy to Hugging Face Spaces:\n",
                        "1. Create a new Space at huggingface.co/new-space\n",
                        "2. Select 'Gradio' as the SDK\n",
                        "3. Upload gradio_app.py as 'app.py'\n",
                        "4. Add requirements.txt with: transformers, torch, gradio\n"
                    ]
                }
            ],
            "source": [
                "# Complete app for HF Spaces\n",
                "spaces_app = '''\n",
                "import gradio as gr\n",
                "from transformers import pipeline\n",
                "import torch\n",
                "\n",
                "# Load models\n",
                "device = 0 if torch.cuda.is_available() else -1\n",
                "classifier = pipeline(\"sentiment-analysis\", device=device)\n",
                "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
                "\n",
                "def analyze_sentiment(text):\n",
                "    if not text.strip():\n",
                "        return {\"Error\": 1.0}\n",
                "    result = classifier(text)[0]\n",
                "    return {\n",
                "        f\"{result['label']} {'üòä' if result['label'] == 'POSITIVE' else 'üò†'}\": result['score'],\n",
                "        \"Other\": 1 - result['score']\n",
                "    }\n",
                "\n",
                "def summarize(text, max_len, min_len):\n",
                "    if len(text) < 50:\n",
                "        return \"Please enter at least 50 characters.\"\n",
                "    result = summarizer(text, max_length=max_len, min_length=min_len)\n",
                "    return result[0]['summary_text']\n",
                "\n",
                "with gr.Blocks(title=\"NLP Toolkit\") as app:\n",
                "    gr.Markdown(\"# üõ†Ô∏è NLP Toolkit\")\n",
                "    \n",
                "    with gr.Tabs():\n",
                "        with gr.TabItem(\"Sentiment\"):\n",
                "            gr.Interface(\n",
                "                fn=analyze_sentiment,\n",
                "                inputs=gr.Textbox(lines=3),\n",
                "                outputs=gr.Label(),\n",
                "                examples=[[\"I love this!\"], [\"This is terrible.\"]]\n",
                "            )\n",
                "        \n",
                "        with gr.TabItem(\"Summarize\"):\n",
                "            gr.Interface(\n",
                "                fn=summarize,\n",
                "                inputs=[\n",
                "                    gr.Textbox(lines=6),\n",
                "                    gr.Slider(50, 200, value=100),\n",
                "                    gr.Slider(20, 80, value=30)\n",
                "                ],\n",
                "                outputs=gr.Textbox()\n",
                "            )\n",
                "\n",
                "app.launch()\n",
                "'''\n",
                "\n",
                "# Save for deployment\n",
                "with open(\"./gradio_app.py\", \"w\") as f:\n",
                "    f.write(spaces_app)\n",
                "\n",
                "print(\"‚úÖ App saved to gradio_app.py\")\n",
                "print(\"\\nTo deploy to Hugging Face Spaces:\")\n",
                "print(\"1. Create a new Space at huggingface.co/new-space\")\n",
                "print(\"2. Select 'Gradio' as the SDK\")\n",
                "print(\"3. Upload gradio_app.py as 'app.py'\")\n",
                "print(\"4. Add requirements.txt with: transformers, torch, gradio\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéØ Student Challenge\n",
                "\n",
                "### Challenge: Create a Custom Demo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Create a Gradio demo with:\n",
                "\n",
                "# 1. Text Generation tab (use \"gpt2\" pipeline)\n",
                "# 2. Named Entity Recognition tab (use \"ner\" pipeline)\n",
                "# 3. Add custom CSS styling\n",
                "# 4. Include example inputs\n",
                "\n",
                "# Hint:\n",
                "# generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
                "# ner = pipeline(\"ner\", grouped_entities=True)\n",
                "\n",
                "# Your solution:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Key Takeaways\n",
                "\n",
                "1. **Gradio simplifies** creating ML demos\n",
                "2. **gr.Interface** is quick, **gr.Blocks** offers more control\n",
                "3. **Public links** let you share demos instantly\n",
                "4. **Hugging Face Spaces** provides free hosting\n",
                "5. **Automatic API** is generated for programmatic access\n",
                "\n",
                "---\n",
                "\n",
                "## ‚û°Ô∏è Next Steps\n",
                "\n",
                "Continue to `03_docker_packaging.md` for containerization!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
